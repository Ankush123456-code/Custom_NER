{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incoming-clock",
   "metadata": {},
   "source": [
    "##### Importing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decreased-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy \n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-prerequisite",
   "metadata": {},
   "source": [
    "### loading csv data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "linear-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"ner.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "digital-garbage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They left after a tense hour-long standoff wit...</td>\n",
       "      <td>O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mr. Egeland said the latest figures show 1.8 m...</td>\n",
       "      <td>B-per I-per O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>He said last week 's tsunami and the massive u...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O B-geo O B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Some 1,27,000 people are known dead .</td>\n",
       "      <td>O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aid is being rushed to the region , but the U....</td>\n",
       "      <td>O O O O O O O O O O B-geo O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lebanese politicians are condemning Friday 's ...</td>\n",
       "      <td>B-gpe O O O B-tim O O O O O O O O B-geo O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hour-long standoff wit...   \n",
       "4  U.N. relief coordinator Jan Egeland said Sunda...   \n",
       "5  Mr. Egeland said the latest figures show 1.8 m...   \n",
       "6  He said last week 's tsunami and the massive u...   \n",
       "7              Some 1,27,000 people are known dead .   \n",
       "8  Aid is being rushed to the region , but the U....   \n",
       "9  Lebanese politicians are condemning Friday 's ...   \n",
       "\n",
       "                                              labels  \n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n",
       "2  O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n",
       "3                              O O O O O O O O O O O  \n",
       "4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  \n",
       "5  B-per I-per O O O O O O O O O O O O O O O O O ...  \n",
       "6  O O O O O O O O O O O O O O O O O O B-geo O B-...  \n",
       "7                                      O O O O O O O  \n",
       "8  O O O O O O O O O O B-geo O O O O O O O O O O ...  \n",
       "9  B-gpe O O O B-tim O O O O O O O O B-geo O O O ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dietary-snowboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "labels    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generous-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47959 entries, 0 to 47958\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    47959 non-null  object\n",
      " 1   labels  47959 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 749.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accredited-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blond-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=list(df[\"text\"])\n",
    "ls2=list(df[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-priest",
   "metadata": {},
   "source": [
    "#### converting text data to this form  TRAIN_DATA = [[text, {\"entities\": [(start, end, label)]}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loved-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc(ls):\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for ele in ls:\n",
    "        if ele in punc:\n",
    "            ls = ls.replace(ele, \"\")\n",
    "    return ls\n",
    "def convert(ls, ls2):\n",
    "    i = 0\n",
    "    l1 = []\n",
    "\n",
    "    while (i < len(ls) and i < len(ls2)):\n",
    "        text1 = punc(ls[i])\n",
    "        text2 = punc(ls2[i])\n",
    "        sep1 = text1.split(\" \")\n",
    "        sep2 = text2.split(\" \")\n",
    "        j = 0\n",
    "        start = 0\n",
    "        l3 = []\n",
    "        k = 0\n",
    "        while (j < len(sep1) and j < len(sep2)):\n",
    "            start = k\n",
    "#             print(start)\n",
    "            if (sep2[j] != \"O\"):\n",
    "                ent = sep2[j]\n",
    "                ent = \"\".join(ent)\n",
    "                end = start + len(sep1[j])\n",
    "                l3.append((start, end, ent[1:len(sep2[j])]))\n",
    "            \n",
    "#             print(len(sep1[j]))\n",
    "            k = k + len(sep1[j])+1\n",
    "            j = j + 1\n",
    "#         text1=text1.split()\n",
    "        if (len(l3) > 0):\n",
    "            l1.append([text1.strip(), {\"entities\": (l3)}])\n",
    "\n",
    "        i = i + 1\n",
    "    train_data = list(l1)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-novelty",
   "metadata": {},
   "source": [
    "### converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "based-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=convert(ls,ls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "underlying-monkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country',\n",
       "  {'entities': [(48, 54, 'geo'), (77, 81, 'geo'), (111, 118, 'gpe')]}],\n",
       " ['Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday  after an IAEA surveillance system begins functioning',\n",
       "  {'entities': [(0, 7, 'gpe'), (87, 96, 'tim'), (107, 111, 'org')]}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chicken-headset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40917"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dependent-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy \n",
    "import pickle\n",
    "import json\n",
    "from spacy.training.example import Example\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-plaintiff",
   "metadata": {},
   "source": [
    "#### dump train data into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confirmed-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('output1.json', 'w') as outfile:\n",
    "    json.dump(train, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-reputation",
   "metadata": {},
   "source": [
    "#### load json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "banner-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "data=load_data(\"output1.json\")\n",
    "train_data=data[0:30000]\n",
    "test_data=data[30000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-holly",
   "metadata": {},
   "source": [
    "#### converting into spacy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "public-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.blank('en')\n",
    "def create_traing(train_data):\n",
    "    db=DocBin()\n",
    "    for text,annot in tqdm(train_data):\n",
    "        doc=nlp.make_doc(text)\n",
    "        ent=[]\n",
    "#         print(annot)\n",
    "        for start,end,label in annot['entities']:\n",
    "            span=doc.char_span(start,end,label=label,alignment_mode=\"strict\")\n",
    "#             print(label)\n",
    "#             print(span)\n",
    "            if span is None:\n",
    "                continue\n",
    "            else:\n",
    "                ent.append(span)\n",
    "        doc.ents=ent\n",
    "        db.add(doc)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-joseph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nervous-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 30000/30000 [00:49<00:00, 606.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10917/10917 [00:16<00:00, 668.00it/s]\n"
     ]
    }
   ],
   "source": [
    "#####     debugging for refernce     ######\n",
    "# for text,annot in tqdm(data[0:]):\n",
    "#     print(annot)\n",
    "#     doc=nlp.make_doc(text)\n",
    "#     for start,end,label in annot[\"entities\"]:\n",
    "#         print(start,end,label)\n",
    "#         print(text[start:end],label)\n",
    "#         span=doc.char_span(start,end,label=label,alignment_mode=\"strict\")\n",
    "#         print(span)\n",
    "train_data=create_traing(train_data)\n",
    "train_data.to_disk(\"./train.spacy\")\n",
    "dev_data=create_traing(test_data)\n",
    "dev_data.to_disk(\"./dev.spacy\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "statewide-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Using CPU\n",
      "\u001b[1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 14:57:29.689739: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
      "2021-07-21 14:57:29.689780: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2021-07-21 14:57:35,244] [INFO] Set up nlp object from config\n",
      "[2021-07-21 14:57:35,257] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-07-21 14:57:35,263] [INFO] Created vocabulary\n",
      "[2021-07-21 14:57:35,263] [INFO] Finished initializing nlp object\n",
      "[2021-07-21 14:58:56,742] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     41.35    9.11    5.48   26.88    0.09\n",
      "  0     200         91.43   3705.62   61.05   63.20   59.05    0.61\n",
      "  0     400        179.25   2405.99   76.00   76.04   75.96    0.76\n",
      "  0     600        212.73   2649.04   79.79   80.61   78.99    0.80\n",
      "  0     800        223.31   2796.84   81.56   82.12   81.02    0.82\n",
      "  0    1000        270.77   3136.67   82.81   83.12   82.51    0.83\n",
      "  0    1200        328.92   3821.08   83.27   83.67   82.87    0.83\n",
      "  0    1400        368.06   4298.29   83.93   84.66   83.21    0.84\n",
      "  0    1600        466.27   4996.56   84.47   85.86   83.13    0.84\n",
      "  0    1800        575.90   6118.05   84.68   85.15   84.21    0.85\n",
      "  0    2000        696.69   7137.58   85.44   86.34   84.56    0.85\n",
      "  1    2200        859.73   7425.08   85.14   85.30   84.99    0.85\n",
      "  1    2400       1026.50   8362.58   85.17   85.71   84.63    0.85\n",
      "  1    2600       1079.72   8658.49   85.72   86.08   85.37    0.86\n",
      "  2    2800       1107.46   8423.64   85.71   85.76   85.66    0.86\n",
      "  2    3000       1168.38   7651.04   86.04   86.41   85.67    0.86\n",
      "  2    3200       1235.82   7658.39   85.58   86.05   85.11    0.86\n",
      "  2    3400       1227.38   7700.54   86.24   86.48   85.99    0.86\n",
      "  3    3600       1198.62   6648.14   85.69   85.76   85.63    0.86\n",
      "  3    3800       1323.32   6825.95   86.16   87.03   85.31    0.86\n",
      "  3    4000       1356.78   7158.11   85.71   86.00   85.42    0.86\n",
      "  4    4200       1365.45   6459.02   85.95   86.39   85.51    0.86\n",
      "  4    4400       1398.68   6295.47   85.99   85.91   86.07    0.86\n",
      "  4    4600       1393.46   6359.34   86.02   86.45   85.59    0.86\n",
      "  5    4800       1374.59   6253.22   85.81   85.96   85.66    0.86\n",
      "  5    5000       1498.78   5786.60   85.09   85.62   84.58    0.85\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-hours",
   "metadata": {},
   "source": [
    "#### load Custom NER model for checking its working fine or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broken-tomato",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    President\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">per</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bush\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">per</span>\n",
       "</mark>\n",
       " has signed legislation that will require screening of all air and sea cargo  and will provide more money to cities deemed to be at high risk of a terrorist attack in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    California\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">geo</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp1 = spacy.load(R\"C:\\Users\\Ankush babu\\Desktop\\Travel insurance\\custom on new dataset\\output\\model-best\") #load the best model\n",
    "doc = nlp1(\"President Bush has signed legislation that will require screening of all air and sea cargo  and will provide more money to cities deemed to be at high risk of a terrorist attack in California\")\n",
    "spacy.displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-poison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
